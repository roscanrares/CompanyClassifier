{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Labeling cu FAISS + DeBERTa\n",
    "\n",
    "Scop:\n",
    "- Folosim embeddings Sentence-BERT + FAISS pentru a selecta Top-K = 22 de etichete candidate.\n",
    "- Validam fiecare eticheta cu un model DeBERTa zero-shot.\n",
    "- Rezultatul: un set final de etichete multi-label, fara antrenare supravegheata.\n"
   ],
   "id": "2f8774183ba6b60c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "import torch"
   ],
   "id": "19336f51624e9c8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inccrcam label-urile si construim index FAISS\n",
    "Presupunem ca:\n",
    "- `insurance_taxonomy.csv` sau `.xlsx` conține coloana `label` cu lista completa de etichete.\n",
    "- Folosim un model Sentence-BERT pentru embeddings.\n"
   ],
   "id": "c74690ba5e30ce82"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "label_file = \"insurance_taxonomy.xlsx\"\n",
    "df_labels = pd.read_excel(label_file)\n",
    "label_list = df_labels[\"label\"].tolist()\n",
    "print(f\"Avem {len(label_list)} etichete disponibile.\")\n",
    "\n",
    "emb_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "label_embeddings = emb_model.encode(label_list, show_progress_bar=True)\n",
    "label_embeddings = np.array(label_embeddings, dtype=\"float32\")\n",
    "\n",
    "embed_dim = label_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(embed_dim)\n",
    "index.add(label_embeddings)"
   ],
   "id": "1d7b3aab252d27cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Încărcăm modelul DeBERTa zero-shot\n",
    "\n",
    "Recomandarea: **MoritzLaurer/deberta-v3-base-mnli** sau alt model specializat pe zero-shot.\n",
    "La nevoie poți folosi BART MNLI (ex. `facebook/bart-large-mnli`) – adaptabil."
   ],
   "id": "dd6c54e506846f25"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "zero_shot_model_name = \"MoritzLaurer/deberta-v3-base-mnli\" #unul dintre modelele nli testate\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\",\n",
    "                                model=zero_shot_model_name,\n",
    "                                device = 0 if torch.cuda.is_available() else -1,\n",
    "                                framework=\"pt\")"
   ],
   "id": "dfece26e382c5f54",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Incarcam companiile si aplicam flow-ul: FAISS -> DeBERTa Zero-Shot\n",
    "\n",
    "- Coloană relevantă: `description` (și, opțional, `business_tags`, `sector`, `category`, `niche`).\n",
    "- Noi folosim doar `description` pentru a determina embedding-ul. \n",
    "- *K = 22* etichete candidate. \n",
    "- DeBERTa zero-shot (multi_label=True) pentru validare finală.\n"
   ],
   "id": "279fd42778c150b4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "companies_file = \"ml_insurance_challenge.csv\"\n",
    "df_comp = pd.read_csv(companies_file)\n",
    "\n",
    "K = 22\n",
    "entail_threshold = 0.3\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(len(df_comp)), desc=\"Procesare intrari\"):\n",
    "    row = df_comp.iloc[i]\n",
    "\n",
    "    description = str(row[\"description\"]).strip()\n",
    "    business_tags = eval(row[\"business_tags\"]) if isinstance(row[\"business_tags\"], str) and row[\"business_tags\"].startswith(\"[\") else []\n",
    "    sector = str(row[\"sector\"]).strip() if pd.notna(row[\"sector\"]) else \"\"\n",
    "    category = str(row[\"category\"]).strip() if pd.notna(row[\"category\"]) else \"\"\n",
    "    niche = str(row[\"niche\"]).strip() if pd.notna(row[\"niche\"]) else \"\"\n",
    "\n",
    "    # combined_text = f\"{description}. Business Tags: {', '.join(business_tags)} Niche: {niche}.\".strip()\n",
    "    # combined_text = f\"{description} . Business Tags: {', '.join(business_tags)}. Sector: {sector}. Category: {category}. Niche: {niche}.\".strip()\n",
    "    combined_text = f\"Description: {description}. This business operates in the {niche} niche. Tags: {', '.join(business_tags)}.\"\n",
    "\n",
    "    if not description:\n",
    "        results.append({\n",
    "            \"description\": description,\n",
    "            \"final_labels\": []\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    desc_emb = emb_model.encode(combined_text, convert_to_tensor=False)\n",
    "    desc_emb = desc_emb.astype(np.float32).reshape(1, -1)\n",
    "\n",
    "    distances, indices = index.search(desc_emb, K)\n",
    "    candidate_labels = [label_list[idx] for idx in indices[0]]\n",
    "    candidate_scores = distances[0] \n",
    "\n",
    "\n",
    "    all_candidate_labels = list(set(candidate_labels) | extra_labels)\n",
    "    classification = zero_shot_classifier(\n",
    "        combined_text,\n",
    "        candidate_labels,\n",
    "        multi_label=True\n",
    "    )\n",
    "\n",
    "    label2score = {lab: score for lab, score in zip(classification[\"labels\"], classification[\"scores\"])}\n",
    "\n",
    "    validated = [lab for lab in candidate_labels if label2score.get(lab, 0) >= entail_threshold]\n",
    "\n",
    "    results.append({\n",
    "        \"description\": description,\n",
    "        \"business_tags\": business_tags,\n",
    "        \"sector\": sector,\n",
    "        \"category\": category,\n",
    "        \"niche\": niche,\n",
    "        \"candidate_labels\": candidate_labels,\n",
    "        \"candidate_sim_scores\": list(candidate_scores),\n",
    "        \"zero_shot_scores\": {lab: float(label2score.get(lab, 0)) for lab in candidate_labels},\n",
    "        \"final_labels\": validated\n",
    "    })"
   ],
   "id": "89bb582a0d98659f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_out = pd.DataFrame(results)\n",
    "output_file = \"final_cox_v15.csv\"\n",
    "df_out.to_csv(output_file, index=False)"
   ],
   "id": "46a2a73c5f4cfc0b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
